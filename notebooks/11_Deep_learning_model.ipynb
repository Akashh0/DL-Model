{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee4e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DeepBallonNet: Complete Deep Learning Pipeline ---\n",
      "‚úÖ Historical data loaded.\n",
      "Training Neural Network...\n",
      "‚úÖ Model Trained.\n",
      "üèÜ Best Threshold: 0.85\n",
      "\n",
      "--- Deep Learning Model Evaluation ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Candidate       1.00      1.00      1.00      8297\n",
      "Top Candidate       1.00      0.08      0.15        12\n",
      "\n",
      "     accuracy                           1.00      8309\n",
      "    macro avg       1.00      0.54      0.58      8309\n",
      " weighted avg       1.00      1.00      1.00      8309\n",
      "\n",
      "\n",
      "--- Predicting 2026 Winners... ---\n",
      "\n",
      "üèÜ Deep Learning Ballon d'Or 2026 Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Gls_league</th>\n",
       "      <th>Gls_ucl</th>\n",
       "      <th>DL_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>Harry Kane</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.572321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Erling Haaland</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.531747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Kylian Mbapp√©</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>Joaqu√≠n Panichelli</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Luis D√≠az</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Vinicius J√∫nior</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Antoine Semenyo</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Juli√°n √Ålvarez</td>\n",
       "      <td>Atl√©tico Madrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Can Uzun</td>\n",
       "      <td>Eint Frankfurt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Ferr√°n Torres</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player            Squad  Gls_league  Gls_ucl  DL_Probability\n",
       "1080          Harry Kane    Bayern Munich          11      4.0        0.572321\n",
       "158       Erling Haaland  Manchester City           9      3.0        0.531747\n",
       "716        Kylian Mbapp√©      Real Madrid           9      5.0        0.523200\n",
       "2083  Joaqu√≠n Panichelli       Strasbourg           7      0.0        0.467136\n",
       "990            Luis D√≠az    Bayern Munich           5      0.0        0.462294\n",
       "656      Vinicius J√∫nior      Real Madrid           5      0.0        0.454021\n",
       "352      Antoine Semenyo      Bournemouth           6      0.0        0.428352\n",
       "453       Juli√°n √Ålvarez  Atl√©tico Madrid           6      1.0        0.419204\n",
       "1270            Can Uzun   Eint Frankfurt           5      1.0        0.415586\n",
       "874        Ferr√°n Torres        Barcelona           4      1.0        0.410949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- DeepBallonNet: Complete Deep Learning Pipeline ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD & PREPARE HISTORICAL DATA\n",
    "# ==============================================================================\n",
    "try:\n",
    "    df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    print(\"‚úÖ Historical data loaded.\")\n",
    "    \n",
    "    # --- STANDARD RENAME (Critical Step) ---\n",
    "    # We rename columns here so training and prediction use the EXACT same names\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Master dataset not found.\")\n",
    "    raise\n",
    "\n",
    "# --- Feature Engineering Function ---\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    if 'Rk_team' in df.columns: trophy = (df['Rk_team'] == 1).astype(int) * 2\n",
    "    else: trophy = 0\n",
    "    if 'UCL_progress' in df.columns:\n",
    "        trophy += (df['UCL_progress'] == 'W').astype(int) * 3\n",
    "        trophy += (df['UCL_progress'] == 'F').astype(int) * 1\n",
    "    df['Trophy_Impact_Score'] = trophy\n",
    "    \n",
    "    df['Big_Game_Score'] = (df.get('Gls_league', 0) * 1.0) + (df.get('Gls_ucl', 0) * 2.5)\n",
    "    return df\n",
    "\n",
    "# --- Setup Data ---\n",
    "ballon_dor_history = { '2023-2024': ['Rodri', 'Vin√≠cius J√∫nior', 'Jude Bellingham', 'Kylian Mbapp√©', 'Harry Kane'], '2022-2023': ['Lionel Messi', 'Erling Haaland', 'Kylian Mbapp√©', 'Kevin De Bruyne', 'Rodri'], '2021-2022': ['Karim Benzema', 'Sadio Man√©', 'Kevin De Bruyne', 'Robert Lewandowski', 'Mohamed Salah'], '2018-2019': ['Lionel Messi', 'Virgil van Dijk', 'Cristiano Ronaldo', 'Sadio Man√©', 'Mohamed Salah'], '2017-2018': ['Luka Modriƒá', 'Cristiano Ronaldo', 'Antoine Griezmann', 'Kylian Mbapp√©', 'Lionel Messi'], '2016-2017': ['Cristiano Ronaldo', 'Lionel Messi', 'Neymar', 'Gianluigi Buffon', 'Luka Modriƒá'], '2015-2016': ['Cristiano Ronaldo', 'Lionel Messi', 'Antoine Griezmann', 'Luis Su√°rez', 'Neymar'], '2014-2015': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar', 'Robert Lewandowski', 'Luis Su√°rez'], '2013-2014': ['Cristiano Ronaldo', 'Lionel Messi', 'Manuel Neuer', 'Arjen Robben', 'Thomas M√ºller'], '2012-2013': ['Cristiano Ronaldo', 'Lionel Messi', 'Franck Rib√©ry', 'Zlatan Ibrahimoviƒá', 'Neymar'], '2011-2012': ['Lionel Messi', 'Cristiano Ronaldo', 'Andr√©s Iniesta', 'Xavi', 'Radamel Falcao'], '2010-2011': ['Lionel Messi', 'Cristiano Ronaldo', 'Xavi', 'Andr√©s Iniesta', 'Wayne Rooney'] }\n",
    "df['Top_Candidate'] = 0\n",
    "for season, players in ballon_dor_history.items():\n",
    "    df.loc[(df['Season'] == season) & (df['Player'].isin(players)), 'Top_Candidate'] = 1\n",
    "\n",
    "df = engineer_features(df)\n",
    "progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'Did Not Qualify': 7}\n",
    "df['UCL_Progress_Rank'] = df['UCL_progress'].str.strip().map(progress_mapping).fillna(7)\n",
    "\n",
    "features = ['Age', 'Min_league', 'Gls_league', 'Ast_league', 'xG_player', 'xAG_player', 'Gls_ucl', 'Ast_ucl', 'Min_ucl', 'Rk_team', 'Pts', 'UCL_Progress_Rank', 'Trophy_Impact_Score', 'Big_Game_Score']\n",
    "X = df[features].fillna(0)\n",
    "y = df['Top_Candidate']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1) # Needed for evaluation\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAIN THE NEURAL NETWORK\n",
    "# ==============================================================================\n",
    "class PrecisionNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PrecisionNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = PrecisionNet(X_train.shape[1])\n",
    "pos_weight = torch.tensor([100.0]) \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "print(\"Training Neural Network...\")\n",
    "for epoch in range(150):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# Find Best Threshold\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(X_test_t)\n",
    "    test_probs = torch.sigmoid(test_logits).numpy()\n",
    "\n",
    "best_prec = 0\n",
    "best_thresh = 0.5\n",
    "for thresh in np.arange(0.5, 0.99, 0.01):\n",
    "    preds = (test_probs > thresh).astype(int)\n",
    "    prec = precision_score(y_test, preds, zero_division=0)\n",
    "    if prec > best_prec:\n",
    "        best_prec = prec\n",
    "        best_thresh = thresh\n",
    "print(f\"üèÜ Best Threshold: {best_thresh:.2f}\")\n",
    "\n",
    "# --- EVALUATION REPORT ---\n",
    "print(\"\\n--- Deep Learning Model Evaluation ---\")\n",
    "final_preds = (test_probs > best_thresh).astype(int)\n",
    "print(classification_report(y_test, final_preds, target_names=['Not Candidate', 'Top Candidate']))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026 WINNER\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Predicting 2026 Winners... ---\")\n",
    "try:\n",
    "    # Load 2026 Data\n",
    "    data_path = '../data/'\n",
    "    df_standings = pd.read_csv(os.path.join(data_path, 'combined_league_standings_2026.csv'))\n",
    "    df_players = pd.read_csv(os.path.join(data_path, 'combined_player_stats_2026.csv'))\n",
    "    df_ucl_p = pd.read_csv(os.path.join(data_path, 'ucl_player_stats_2026.csv'))\n",
    "    df_ucl_t = pd.read_csv(os.path.join(data_path, 'ucl_team_progress_2026.csv'))\n",
    "\n",
    "    # Clean & Merge\n",
    "    current_season = '2025-2026'\n",
    "    for d in [df_standings, df_players, df_ucl_p, df_ucl_t]:\n",
    "        d['Season'] = current_season\n",
    "        d.columns = d.columns.str.strip()\n",
    "        if 'Player' in d.columns: d['Player'] = d['Player'].str.strip()\n",
    "        if 'Squad' in d.columns: d['Squad'] = d['Squad'].str.strip()\n",
    "        \n",
    "        # Clean Squad Names for 2026\n",
    "        if 'Squad' in d.columns:\n",
    "            d['Squad'] = d['Squad'].astype(str).apply(lambda x: ' '.join(x.split(' ')[1:]) if len(x.split(' ')) > 1 and x.split(' ')[0] in ['eng', 'es', 'de', 'it', 'fr'] else x)\n",
    "            replacements = {'Paris S-G': 'Paris Saint-Germain', 'Inter': 'Internazionale', 'Manchester Utd': 'Manchester United', 'Leverkusen': 'Bayer Leverkusen'}\n",
    "            d['Squad'] = d['Squad'].replace(replacements)\n",
    "\n",
    "    merge_keys = ['Squad', 'Season']\n",
    "    if 'League' in df_players.columns and 'League' in df_standings.columns: merge_keys.append('League')\n",
    "    \n",
    "    df_2026 = pd.merge(df_players, df_standings, on=merge_keys, how='left', suffixes=('_player', '_team'))\n",
    "    df_2026 = pd.merge(df_2026, df_ucl_p[['Player', 'Squad', 'Season', 'Gls', 'Ast']], on=['Player', 'Squad', 'Season'], how='left', suffixes=('_league', '_ucl'))\n",
    "    df_2026 = pd.merge(df_2026, df_ucl_t[['Squad', 'Season', 'UCL_progress']], on=['Squad', 'Season'], how='left')\n",
    "    \n",
    "    # Cleanup\n",
    "    for c in ['Gls_ucl', 'Ast_ucl']: \n",
    "        if c in df_2026.columns: df_2026[c] = df_2026[c].fillna(0)\n",
    "    df_2026['UCL_progress'].fillna('Did Not Qualify', inplace=True)\n",
    "\n",
    "    # --- RENAME TO MATCH TRAINING (Critical) ---\n",
    "    rename_map_2026 = {\n",
    "        'xG': 'xG_player', 'xAG': 'xAG_player', \n",
    "        'Rk': 'Rk_team', 'Pts': 'Pts',\n",
    "        'Min': 'Min_league', 'Gls': 'Gls_league', 'Ast': 'Ast_league',\n",
    "        'UCL_Progress': 'UCL_progress'\n",
    "    }\n",
    "    df_2026.rename(columns=rename_map_2026, inplace=True, errors='ignore')\n",
    "\n",
    "    # Engineer Features\n",
    "    df_2026 = engineer_features(df_2026)\n",
    "    progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'League Phase': 6, 'Did Not Qualify': 7}\n",
    "    df_2026['UCL_Progress_Rank'] = df_2026['UCL_progress'].str.strip().map(progress_mapping).fillna(7)\n",
    "\n",
    "    # Select & Scale\n",
    "    for col in features:\n",
    "        if col not in df_2026.columns: df_2026[col] = 0\n",
    "        df_2026[col] = pd.to_numeric(df_2026[col], errors='coerce')\n",
    "    \n",
    "    X_live = df_2026[features].fillna(0)\n",
    "    X_live_scaled = scaler.transform(X_live)\n",
    "    X_live_tensor = torch.tensor(X_live_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_live_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy().flatten()\n",
    "    \n",
    "    df_2026['DL_Probability'] = probs\n",
    "    \n",
    "    print(f\"\\nüèÜ Deep Learning Ballon d'Or 2026 Predictions:\")\n",
    "    display(df_2026.sort_values(by='DL_Probability', ascending=False)[['Player', 'Squad', 'Gls_league', 'Gls_ucl', 'DL_Probability']].head(10))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d0b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Elite High-Precision UCL Model ---\n",
      "Training Elite Ensemble...\n",
      "‚úÖ Model Trained.\n",
      "üèÜ Optimal Threshold: 0.40\n",
      "\n",
      "--- Elite Model Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not Winner       0.98      0.89      0.93        45\n",
      "      Winner       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.63      0.78      0.67        48\n",
      "weighted avg       0.93      0.88      0.90        48\n",
      "\n",
      "\n",
      "--- 2026 UCL Winner Prediction ---\n",
      "Top 10 Contenders:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Squad</th>\n",
       "      <th>Win_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>0.171574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>0.034413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Marseille</td>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.010828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Napoli</td>\n",
       "      <td>0.009711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Dortmund</td>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Internazionale</td>\n",
       "      <td>0.004316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Squad  Win_Prob\n",
       "217        Bayern Munich  0.171574\n",
       "390  Paris Saint-Germain  0.034413\n",
       "382            Marseille  0.015267\n",
       "113            Barcelona  0.012749\n",
       "12               Arsenal  0.010828\n",
       "4              Liverpool  0.010660\n",
       "294               Napoli  0.009711\n",
       "204             Dortmund  0.009545\n",
       "110          Real Madrid  0.006659\n",
       "290       Internazionale  0.004316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training Elite High-Precision UCL Model ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD & PREPARE HISTORICAL DATA\n",
    "# ==============================================================================\n",
    "try:\n",
    "    historical_df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    historical_df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError: raise\n",
    "\n",
    "# --- Feature Engineering Function (Robust) ---\n",
    "def engineer_elite_features(df):\n",
    "    df = df.copy()\n",
    "    league_weights = {'Premier League': 1.0, 'La Liga': 0.95, 'Bundesliga': 0.85, 'Serie A': 0.85, 'Ligue 1': 0.75}\n",
    "    \n",
    "    # Handle missing 'League' column gracefully\n",
    "    if 'League' in df.columns:\n",
    "        df['League_Weight'] = df['League'].map(league_weights).fillna(0.7)\n",
    "        df['Is_Big_5'] = df['League'].isin(league_weights.keys()).astype(int)\n",
    "    else:\n",
    "        # Default weight if League is missing (assumes reasonably strong teams)\n",
    "        df['League_Weight'] = 0.85 \n",
    "        df['Is_Big_5'] = 1 \n",
    "\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Adj_Pts_Per_Game'] = (df['Pts'] / df['MP_team']) * df['League_Weight']\n",
    "    df['Adj_GD_Per_Game'] = (df['GD'] / df['MP_team']) * df['League_Weight']\n",
    "    \n",
    "    # Use aggregated column names directly\n",
    "    df['Squad_Goals'] = df.get('Agg_Gls_league', 0)\n",
    "    df['Squad_xG'] = df.get('Agg_xG', 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare Data\n",
    "ucl_df = historical_df[historical_df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "# Aggregate player stats\n",
    "player_agg = historical_df.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={\n",
    "    'Gls_league': 'Agg_Gls_league', \n",
    "    'xG_player': 'Agg_xG'\n",
    "})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "ucl_df = engineer_elite_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "# Define Features\n",
    "features = ['Adj_Pts_Per_Game', 'Adj_GD_Per_Game', 'Is_Big_5', 'Squad_Goals', 'Squad_xG']\n",
    "for col in features:\n",
    "    if col not in team_level_df.columns: team_level_df[col] = 0\n",
    "\n",
    "X = team_level_df[features].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAINING (Elite Ensemble)\n",
    "# ==============================================================================\n",
    "print(\"Training Elite Ensemble...\")\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ucl_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ucl_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# Optimal Threshold\n",
    "probs = ucl_model.predict_proba(X_test_sc)[:, 1]\n",
    "best_thresh, best_f1 = 0.5, 0\n",
    "for t in np.arange(0.1, 0.9, 0.05):\n",
    "    preds = (probs >= t).astype(int)\n",
    "    score = f1_score(y_test, preds)\n",
    "    if score > best_f1: best_f1, best_thresh = score, t\n",
    "\n",
    "print(f\"üèÜ Optimal Threshold: {best_thresh:.2f}\")\n",
    "print(\"\\n--- Elite Model Report ---\")\n",
    "print(classification_report(y_test, (probs >= best_thresh).astype(int), target_names=['Not Winner', 'Winner']))\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2026 UCL Winner Prediction ---\")\n",
    "try:\n",
    "    # Load 2026 data\n",
    "    d_p = pd.read_csv('../data/combined_player_stats_2026.csv')\n",
    "    d_l = pd.read_csv('../data/combined_league_standings_2026.csv')\n",
    "    d_up = pd.read_csv('../data/ucl_team_progress_2026.csv')\n",
    "    d_us = pd.read_csv('../data/ucl_player_stats_2026.csv')\n",
    "    \n",
    "    current_season = '2025-2026'\n",
    "    for d in [d_p, d_l, d_up, d_us]: \n",
    "        d['Season']=current_season; d.columns=d.columns.str.strip()\n",
    "        if 'Squad' in d.columns: d['Squad']=d['Squad'].str.strip().replace({'Paris S-G':'Paris Saint-Germain','Inter':'Internazionale','Manchester Utd':'Manchester United','Leverkusen':'Bayer Leverkusen'})\n",
    "\n",
    "    m_k = ['Squad', 'Season']\n",
    "    if 'League' in d_p.columns and 'League' in d_l.columns: m_k.append('League')\n",
    "    df_26 = pd.merge(d_p, d_l, on=m_k, how='left', suffixes=('_player', '_team'))\n",
    "    df_26 = pd.merge(df_26, d_us[['Player','Squad','Season']], on=['Player','Squad','Season'], how='left')\n",
    "    df_26 = pd.merge(df_26, d_up, on=['Squad','Season'], how='left')\n",
    "    if 'UCL_Progress' in df_26.columns: df_26.rename(columns={'UCL_Progress':'UCL_progress'}, inplace=True)\n",
    "    df_26['UCL_progress'].fillna('Did Not Qualify', inplace=True)\n",
    "    \n",
    "    ucl_26 = df_26[df_26['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "    rename_26 = {'Gls':'Gls_league', 'xG':'xG_player', 'Pts':'Pts', 'MP':'MP_team', 'W':'W', 'GD':'GD', 'Rk':'Rk_team'}\n",
    "    ucl_26.rename(columns=rename_26, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Aggregation\n",
    "    p_agg = ucl_26.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Agg_Gls_league', 'xG_player': 'Agg_xG'})\n",
    "    ucl_26 = pd.merge(ucl_26, p_agg, on=['Squad', 'Season'], how='left')\n",
    "    ucl_26 = ucl_26.drop_duplicates(subset=['Squad'])\n",
    "    \n",
    "    # Feature Engineering (Now Safe against missing 'League' column)\n",
    "    ucl_26 = engineer_elite_features(ucl_26)\n",
    "    \n",
    "    # Select Best Features & Scale\n",
    "    for col in features:\n",
    "        if col not in ucl_26.columns: ucl_26[col] = 0\n",
    "    \n",
    "    X_live = ucl_26[features].fillna(0)\n",
    "    # Use the same scaler from training!\n",
    "    X_live_sc = pd.DataFrame(scaler.transform(X_live), columns=features)\n",
    "    \n",
    "    # Predict\n",
    "    ucl_26['Win_Prob'] = ucl_model.predict_proba(X_live_sc)[:, 1]\n",
    "    print(\"Top 10 Contenders:\")\n",
    "    cols = ['Squad', 'Win_Prob']\n",
    "    if 'League' in ucl_26.columns: cols.insert(1, 'League')\n",
    "    display(ucl_26[cols].sort_values(by='Win_Prob', ascending=False).head(10))\n",
    "\n",
    "except Exception as e: print(f\"Prediction Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a50b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training UCL Ensemble Model ---\n",
      "‚úÖ Ensemble Model Trained.\n",
      "\n",
      ">>> Evaluating UCL Winner Model...\n",
      "\n",
      "--- Advanced Evaluation: Ensemble ---\n",
      "üèÜ Optimal Threshold: 0.2140\n",
      "   Max F1-Score: 0.1429\n",
      "   Precision at Optimal: 0.0909\n",
      "   Recall at Optimal:    0.3333\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 28.3\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Train and Evaluate UCL Ensemble Model ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training UCL Ensemble Model ---\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Data not found!\")\n",
    "\n",
    "# 2. Feature Engineering (Elite UCL)\n",
    "def engineer_ucl_features(df):\n",
    "    df = df.copy()\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Pts_Per_Game'] = df['Pts'] / df['MP_team']\n",
    "    df['Goal_Diff_Per_Game'] = df['GD'] / df['MP_team']\n",
    "    df['Win_Rate'] = df['W'] / df['MP_team']\n",
    "    df['Dominance_Score'] = (df['Win_Rate'] * 0.7) + (df['Goal_Diff_Per_Game'] * 0.3)\n",
    "    df['League_Pedigree'] = 1 / df['Rk_team'].replace(0, 20)\n",
    "    return df\n",
    "\n",
    "# 3. Prepare Team-Level Data\n",
    "ucl_df = df[df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "player_agg = df.groupby(['Squad', 'Season'])[['Gls_league', 'Ast_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Squad_Goals', 'Ast_league': 'Squad_Ast', 'xG_player': 'Squad_xG'})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "\n",
    "ucl_df = engineer_ucl_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "features_ucl = ['Pts_Per_Game', 'Goal_Diff_Per_Game', 'Win_Rate', 'Dominance_Score', 'League_Pedigree', 'Squad_Goals', 'Squad_xG', 'xG_team']\n",
    "# Handle missing xG_team for old seasons\n",
    "if 'xG_team' not in team_level_df.columns: team_level_df['xG_team'] = 0\n",
    "\n",
    "X = team_level_df[features_ucl].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Train Ensemble\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42, eval_metric='logloss')\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ensemble_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Ensemble Model Trained.\")\n",
    "\n",
    "# 5. Run Advanced Evaluation (Using your function)\n",
    "if 'evaluate_model_advanced' in locals():\n",
    "    print(\"\\n>>> Evaluating UCL Winner Model...\")\n",
    "    evaluate_model_advanced(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "    calculate_top_k_proxy(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è evaluation functions not found. Please run the previous cell containing 'evaluate_model_advanced'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb828a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Advanced Evaluation: Deep Learning (Ballon d'Or) ---\n",
      "üèÜ Optimal Threshold: 0.7485\n",
      "   Max F1-Score: 0.2857\n",
      "   Precision at Optimal: 0.3333\n",
      "   Recall at Optimal:    0.2500\n",
      "\n",
      "--- Advanced Evaluation: Ensemble (UCL) ---\n",
      "üèÜ Optimal Threshold: 0.0140\n",
      "   Max F1-Score: 0.1290\n",
      "   Precision at Optimal: 0.0714\n",
      "   Recall at Optimal:    0.6667\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Deep Learning): 171.2\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 30.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# --- 1. Define the Advanced Evaluation Function (FIXED) ---\n",
    "def evaluate_model_advanced(model, X_test, y_test, model_type=\"Deep Learning\"):\n",
    "    print(f\"\\n--- Advanced Evaluation: {model_type} ---\")\n",
    "    \n",
    "    # Get Probabilities\n",
    "    # FIX: Check if \"Deep Learning\" is IN the string, not just equal to it\n",
    "    if \"Deep Learning\" in model_type:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X_test, torch.Tensor):\n",
    "                X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "            # Forward pass + Sigmoid\n",
    "            probs = torch.sigmoid(model(X_test)).numpy().flatten()\n",
    "            \n",
    "            if isinstance(y_test, torch.Tensor):\n",
    "                y_true = y_test.numpy().flatten()\n",
    "            else:\n",
    "                y_true = y_test\n",
    "    else: # Ensemble / XGBoost\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        y_true = y_test\n",
    "\n",
    "    # 2. Find Optimal Threshold (Maximize F1)\n",
    "    # Handle NaNs in y_true (just in case)\n",
    "    mask = ~np.isnan(y_true)\n",
    "    y_true = y_true[mask]\n",
    "    probs = probs[mask]\n",
    "    \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, probs)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    # Safety check for index bounds\n",
    "    if best_idx < len(thresholds):\n",
    "        best_thresh = thresholds[best_idx]\n",
    "    else:\n",
    "        best_thresh = 0.5\n",
    "        \n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    \n",
    "    print(f\"üèÜ Optimal Threshold: {best_thresh:.4f}\")\n",
    "    print(f\"   Max F1-Score: {best_f1:.4f}\")\n",
    "    print(f\"   Precision at Optimal: {precisions[best_idx]:.4f}\")\n",
    "    print(f\"   Recall at Optimal:    {recalls[best_idx]:.4f}\")\n",
    "\n",
    "    return best_thresh\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. RUN ADVANCED EVALUATION (with Reconstructed Data)\n",
    "# ==============================================================================\n",
    "\n",
    "# Note: We assume the data reconstruction part from the previous cell ran successfully\n",
    "# and X_test_b_tensor, y_test_b_tensor, X_test_u_scaled, y_test_u are available.\n",
    "\n",
    "if 'model' in locals():\n",
    "    # Fix: String matching is now handled inside the function\n",
    "    best_thresh_bdo = evaluate_model_advanced(model, X_test_b_tensor, y_test_b, \"Deep Learning (Ballon d'Or)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'model' (Deep Learning) not found in memory.\")\n",
    "\n",
    "if 'ensemble_model' in locals():\n",
    "    best_thresh_ucl = evaluate_model_advanced(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble (UCL)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'ensemble_model' not found in memory.\")\n",
    "\n",
    "\n",
    "# --- 3. Top-K Accuracy Proxy ---\n",
    "def calculate_top_k_proxy(model, X, y, model_type=\"Deep Learning\"):\n",
    "    if model_type == \"Deep Learning\":\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "             if not isinstance(X, torch.Tensor): X = torch.tensor(X, dtype=torch.float32)\n",
    "             probs = torch.sigmoid(model(X)).numpy().flatten()\n",
    "    else:\n",
    "        probs = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    results = pd.DataFrame({'Actual': y, 'Prob': probs})\n",
    "    winners = results[results['Actual'] == 1]\n",
    "    \n",
    "    if not winners.empty:\n",
    "        results['Rank'] = results['Prob'].rank(ascending=False)\n",
    "        avg_winner_rank = results[results['Actual'] == 1]['Rank'].mean()\n",
    "        print(f\"\\nüìä Average Rank of True Winners in Test Set ({model_type}): {avg_winner_rank:.1f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No winners found in test set for {model_type}.\")\n",
    "\n",
    "if 'model' in locals(): calculate_top_k_proxy(model, X_test_b_tensor, y_test_b, \"Deep Learning\")\n",
    "if 'ensemble_model' in locals(): calculate_top_k_proxy(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
