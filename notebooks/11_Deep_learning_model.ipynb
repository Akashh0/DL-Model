{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DeepBallonNet: Ballon d'Or Deep Learning Pipeline ---\n",
      "‚úÖ Historical data loaded.\n",
      "Training Neural Network...\n",
      "‚úÖ Model Trained.\n",
      "üèÜ Best Threshold: 0.86\n",
      "\n",
      "--- Deep Learning Model Evaluation ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Candidate       1.00      1.00      1.00      8297\n",
      "Top Candidate       1.00      0.08      0.15        12\n",
      "\n",
      "     accuracy                           1.00      8309\n",
      "    macro avg       1.00      0.54      0.58      8309\n",
      " weighted avg       1.00      1.00      1.00      8309\n",
      "\n",
      "\n",
      "--- Predicting 2026 Ballon d'Or Candidates... ---\n",
      "‚úÖ 2026 Master Dataset loaded successfully.\n",
      "Top 10 Candidates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Gls_league</th>\n",
       "      <th>Gls_ucl</th>\n",
       "      <th>BallonDor_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Pierre-Emerick Aubameyang</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>√Ålex Grimaldo</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Kylian Mbapp√©</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Erling Haaland</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Nicolas P√©p√©</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Joshua Kimmich</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>Vitinha</td>\n",
       "      <td>Paris S-G</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Konrad Laimer</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Aitor Paredes</td>\n",
       "      <td>Athletic Club</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>Nuno Mendes</td>\n",
       "      <td>Paris S-G</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Player            Squad  Gls_league  Gls_ucl  \\\n",
       "1861  Pierre-Emerick Aubameyang        Marseille           4      1.0   \n",
       "1070              √Ålex Grimaldo       Leverkusen           4      1.0   \n",
       "746               Kylian Mbapp√©      Real Madrid          13      5.0   \n",
       "163              Erling Haaland  Manchester City          14      5.0   \n",
       "807                Nicolas P√©p√©       Villarreal           2      0.0   \n",
       "1130             Joshua Kimmich    Bayern Munich           1      0.0   \n",
       "2261                    Vitinha        Paris S-G           1      1.0   \n",
       "1149              Konrad Laimer    Bayern Munich           1      0.0   \n",
       "799               Aitor Paredes    Athletic Club           1      0.0   \n",
       "2117                Nuno Mendes        Paris S-G           2      2.0   \n",
       "\n",
       "      BallonDor_Probability  \n",
       "1861               0.999899  \n",
       "1070               0.999895  \n",
       "746                0.999890  \n",
       "163                0.999866  \n",
       "807                0.999852  \n",
       "1130               0.999838  \n",
       "2261               0.999838  \n",
       "1149               0.999828  \n",
       "799                0.999817  \n",
       "2117               0.999816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- DeepBallonNet: Ballon d'Or Deep Learning Pipeline ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. HELPER FUNCTIONS & SETUP\n",
    "# ==============================================================================\n",
    "def engineer_features(df):\n",
    "    df_featured = df.copy()\n",
    "    # Handle case sensitivity\n",
    "    if 'UCL_Progress' in df_featured.columns:\n",
    "        df_featured.rename(columns={'UCL_Progress': 'UCL_progress'}, inplace=True)\n",
    "        \n",
    "    trophy_score = (df_featured.get('Rk_team', 0) == 1).astype(int) * 2\n",
    "    if 'UCL_progress' in df_featured.columns:\n",
    "        trophy_score += (df_featured['UCL_progress'] == 'W').astype(int) * 3\n",
    "        trophy_score += (df_featured['UCL_progress'] == 'F').astype(int) * 1\n",
    "    df_featured['Trophy_Impact_Score'] = trophy_score\n",
    "\n",
    "    df_featured['Big_Game_Score'] = (df_featured.get('Gls_league', 0) * 1.0) + \\\n",
    "                                    (df_featured.get('Ast_league', 0) * 0.5) + \\\n",
    "                                    (df_featured.get('Gls_ucl', 0) * 2.0) + \\\n",
    "                                    (df_featured.get('Ast_ucl', 0) * 1.0)\n",
    "    \n",
    "    df_featured['Dominance_Ratio'] = df_featured.get('Gls_league', 0) / df_featured.get('GF', 1).replace(0, 1)\n",
    "    return df_featured\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. LOAD & PREPARE HISTORICAL TRAINING DATA\n",
    "# ==============================================================================\n",
    "try:\n",
    "    df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    print(\"‚úÖ Historical data loaded.\")\n",
    "    # Rename columns to standard names for training\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Master dataset not found.\")\n",
    "    raise\n",
    "\n",
    "# Create Target\n",
    "ballon_dor_history = {\n",
    "    '2024-2025': ['Ousmane Dembele', 'Lamine Yamal', 'Vitinha', 'Raphinha', 'Mohammed Salah', 'Kylian Mbappe', 'Achraf Hakimi', 'Desire Doue', 'Kvicha Kvaratskhelia', 'Nuno Mendes'],\n",
    "    '2023-2024': ['Rodri', 'Vin√≠cius J√∫nior', 'Jude Bellingham', 'Dani Carvajal', 'Lautaro Martinez', 'Toni Kroos', 'Kylian Mbapp√©', 'Harry Kane', 'Phil Foden', 'Lamine Yamal'],\n",
    "    '2022-2023': ['Lionel Messi', 'Erling Haaland', 'Kylian Mbapp√©', 'Kevin De Bruyne', 'Rodri', 'Vin√≠cius J√∫nior', 'Juli√°n √Ålvarez', 'Victor Osimhen', 'Bernardo Silva', 'Luka Modriƒá'],\n",
    "    '2021-2022': ['Karim Benzema', 'Sadio Man√©', 'Kevin De Bruyne', 'Robert Lewandowski', 'Mohamed Salah', 'Kylian Mbapp√©', 'Thibaut Courtois', 'Vin√≠cius J√∫nior', 'Luka Modriƒá', 'Erling Haaland'],\n",
    "    '2020-2021': ['Lionel Messi', 'Robert Lewandowski', 'Jorginho', 'Karim Benzema', 'N\\'Golo Kant√©', 'Cristiano Ronaldo', 'Mohamed Salah', 'Kevin De Bruyne', 'Kylian Mbapp√©', 'Gianluigi Donnarumma'],\n",
    "    '2018-2019': ['Lionel Messi', 'Virgil van Dijk', 'Cristiano Ronaldo', 'Sadio Man√©', 'Mohamed Salah', 'Kylian Mbapp√©', 'Alisson', 'Robert Lewandowski', 'Bernardo Silva', 'Riyad Mahrez'],\n",
    "    '2017-2018': ['Luka Modriƒá', 'Cristiano Ronaldo', 'Antoine Griezmann', 'Kylian Mbapp√©', 'Lionel Messi', 'Mohamed Salah', 'Rapha√´l Varane', 'Eden Hazard', 'Kevin De Bruyne', 'Harry Kane'],\n",
    "    '2016-2017': ['Cristiano Ronaldo', 'Lionel Messi', 'Neymar', 'Gianluigi Buffon', 'Luka Modriƒá', 'Sergio Ramos', 'Kylian Mbapp√©', 'N\\'Golo Kant√©', 'Robert Lewandowski', 'Harry Kane'],\n",
    "    '2015-2016': ['Cristiano Ronaldo', 'Lionel Messi', 'Antoine Griezmann', 'Luis Su√°rez', 'Neymar', 'Gareth Bale', 'Riyad Mahrez', 'Jamie Vardy', 'Gianluigi Buffon', 'Pepe'],\n",
    "    '2014-2015': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar', 'Robert Lewandowski', 'Luis Su√°rez', 'Thomas M√ºller', 'Manuel Neuer', 'Eden Hazard', 'Andr√©s Iniesta', 'Alexis S√°nchez'],\n",
    "    '2013-2014': ['Cristiano Ronaldo', 'Lionel Messi', 'Manuel Neuer', 'Arjen Robben', 'Thomas M√ºller', 'Philipp Lahm', 'Neymar', 'James Rodr√≠guez', 'Toni Kroos', '√Ångel Di Mar√≠a'],\n",
    "    '2012-2013': ['Cristiano Ronaldo', 'Lionel Messi', 'Franck Rib√©ry', 'Zlatan Ibrahimoviƒá', 'Neymar', 'Andr√©s Iniesta', 'Robin van Persie', 'Arjen Robben', 'Gareth Bale', 'Andrea Pirlo'],\n",
    "    '2011-2012': ['Lionel Messi', 'Cristiano Ronaldo', 'Andr√©s Iniesta', 'Xavi', 'Radamel Falcao', 'Iker Casillas', 'Andrea Pirlo', 'Didier Drogba', 'Robin van Persie', 'Zlatan Ibrahimoviƒá'],\n",
    "    '2010-2011': ['Lionel Messi', 'Cristiano Ronaldo', 'Xavi', 'Andr√©s Iniesta', 'Wayne Rooney', 'Luis Su√°rez', 'Diego Forl√°n', 'Samuel Eto\\'o', 'Iker Casillas', 'Neymar']\n",
    "}\n",
    "\n",
    "df['Top_Candidate'] = 0\n",
    "for season, players in ballon_dor_history.items():\n",
    "    df.loc[(df['Season'] == season) & (df['Player'].isin(players)), 'Top_Candidate'] = 1\n",
    "\n",
    "# Feature Engineering\n",
    "df = engineer_features(df)\n",
    "progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'Did Not Qualify': 7}\n",
    "df['UCL_Progress_Rank'] = df['UCL_progress'].str.strip().map(progress_mapping).fillna(7)\n",
    "\n",
    "features = ['Age', 'Min_league', 'Gls_league', 'Ast_league', 'xG_player', 'xAG_player', 'Gls_ucl', 'Ast_ucl', 'Min_ucl', 'Rk_team', 'Pts', 'UCL_Progress_Rank', 'Trophy_Impact_Score', 'Big_Game_Score', 'Dominance_Ratio']\n",
    "X = df[features].fillna(0)\n",
    "y = df['Top_Candidate']\n",
    "\n",
    "# Split, Balance (SMOTE), and Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train_res.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1) # Needed for evaluation\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TRAIN THE NEURAL NETWORK\n",
    "# ==============================================================================\n",
    "class PrecisionNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PrecisionNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.model(x)\n",
    "\n",
    "model = PrecisionNet(X_train.shape[1])\n",
    "pos_weight = torch.tensor([100.0]) \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "print(\"Training Neural Network...\")\n",
    "for epoch in range(150):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# Find Best Threshold\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_probs = torch.sigmoid(model(X_test_t)).numpy()\n",
    "best_prec, best_thresh = 0, 0.5\n",
    "for thresh in np.arange(0.5, 0.99, 0.01):\n",
    "    preds = (test_probs > thresh).astype(int)\n",
    "    prec = precision_score(y_test, preds, zero_division=0)\n",
    "    if prec > best_prec: best_prec, best_thresh = prec, thresh\n",
    "print(f\"üèÜ Best Threshold: {best_thresh:.2f}\")\n",
    "print(\"\\n--- Deep Learning Model Evaluation ---\")\n",
    "print(classification_report(y_test, (test_probs > best_thresh).astype(int), target_names=['Not Candidate', 'Top Candidate']))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. PREDICT 2026 WINNER (FROM MASTER FILE)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Predicting 2026 Ballon d'Or Candidates... ---\")\n",
    "try:\n",
    "    # --- LOAD MASTER DATASET DIRECTLY ---\n",
    "    master_df_2026 = pd.read_csv('../data/master_dataset_2026.csv')\n",
    "    print(\"‚úÖ 2026 Master Dataset loaded successfully.\")\n",
    "\n",
    "    bdo_df = master_df_2026.copy()\n",
    "    \n",
    "    # Rename columns to match training data exactly\n",
    "    rename_map_2026 = {'xG': 'xG_player', 'xAG': 'xAG_player', 'Rk': 'Rk_team', 'Pts': 'Pts', 'UCL_Progress': 'UCL_progress'}\n",
    "    bdo_df.rename(columns=rename_map_2026, inplace=True, errors='ignore')\n",
    "\n",
    "    # Handle duplicates (safety check)\n",
    "    bdo_df = bdo_df.loc[:,~bdo_df.columns.duplicated()]\n",
    "\n",
    "    # Feature Engineering\n",
    "    bdo_df = engineer_features(bdo_df)\n",
    "    progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'League Phase': 6, 'Did Not Qualify': 7}\n",
    "    if 'UCL_progress' in bdo_df.columns:\n",
    "        bdo_df['UCL_Progress_Rank'] = bdo_df['UCL_progress'].str.strip().map(progress_mapping).fillna(7)\n",
    "    else:\n",
    "        bdo_df['UCL_Progress_Rank'] = 7\n",
    "\n",
    "    # Select & Scale\n",
    "    for col in features:\n",
    "        if col not in bdo_df.columns: bdo_df[col] = 0\n",
    "        # If duplicate columns exist, take the first one\n",
    "        if isinstance(bdo_df[col], pd.DataFrame):\n",
    "            bdo_df[col] = bdo_df[col].iloc[:, 0]\n",
    "        bdo_df[col] = pd.to_numeric(bdo_df[col], errors='coerce')\n",
    "    \n",
    "    X_live = bdo_df[features].fillna(0)\n",
    "    X_live_scaled = scaler.transform(X_live)\n",
    "    X_live_tensor = torch.tensor(X_live_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_live_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy().flatten()\n",
    "    \n",
    "    bdo_df['BallonDor_Probability'] = probs\n",
    "    \n",
    "    print(\"Top 10 Candidates:\")\n",
    "    # Sort and drop player duplicates to show unique best candidates\n",
    "    bdo_display = bdo_df.sort_values(by='BallonDor_Probability', ascending=False).drop_duplicates(subset=['Player'])\n",
    "    display(bdo_display[['Player', 'Squad', 'Gls_league', 'Gls_ucl', 'BallonDor_Probability']].head(10))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d0b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Elite High-Precision UCL Model ---\n",
      "Training Elite Ensemble...\n",
      "‚úÖ Model Trained.\n",
      "üèÜ Optimal Threshold: 0.40\n",
      "\n",
      "--- Elite Model Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not Winner       0.98      0.89      0.93        45\n",
      "      Winner       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.63      0.78      0.67        48\n",
      "weighted avg       0.93      0.88      0.90        48\n",
      "\n",
      "\n",
      "--- 2026 UCL Winner Prediction ---\n",
      "Top 10 Contenders:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Squad</th>\n",
       "      <th>Win_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>0.171574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>0.034413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Marseille</td>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.010828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Napoli</td>\n",
       "      <td>0.009711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Dortmund</td>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Internazionale</td>\n",
       "      <td>0.004316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Squad  Win_Prob\n",
       "217        Bayern Munich  0.171574\n",
       "390  Paris Saint-Germain  0.034413\n",
       "382            Marseille  0.015267\n",
       "113            Barcelona  0.012749\n",
       "12               Arsenal  0.010828\n",
       "4              Liverpool  0.010660\n",
       "294               Napoli  0.009711\n",
       "204             Dortmund  0.009545\n",
       "110          Real Madrid  0.006659\n",
       "290       Internazionale  0.004316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training Elite High-Precision UCL Model ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD & PREPARE HISTORICAL DATA\n",
    "# ==============================================================================\n",
    "try:\n",
    "    historical_df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    historical_df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError: raise\n",
    "\n",
    "# --- Feature Engineering Function (Robust) ---\n",
    "def engineer_elite_features(df):\n",
    "    df = df.copy()\n",
    "    league_weights = {'Premier League': 1.0, 'La Liga': 0.95, 'Bundesliga': 0.85, 'Serie A': 0.85, 'Ligue 1': 0.75}\n",
    "    \n",
    "    # Handle missing 'League' column gracefully\n",
    "    if 'League' in df.columns:\n",
    "        df['League_Weight'] = df['League'].map(league_weights).fillna(0.7)\n",
    "        df['Is_Big_5'] = df['League'].isin(league_weights.keys()).astype(int)\n",
    "    else:\n",
    "        # Default weight if League is missing (assumes reasonably strong teams)\n",
    "        df['League_Weight'] = 0.85 \n",
    "        df['Is_Big_5'] = 1 \n",
    "\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Adj_Pts_Per_Game'] = (df['Pts'] / df['MP_team']) * df['League_Weight']\n",
    "    df['Adj_GD_Per_Game'] = (df['GD'] / df['MP_team']) * df['League_Weight']\n",
    "    \n",
    "    # Use aggregated column names directly\n",
    "    df['Squad_Goals'] = df.get('Agg_Gls_league', 0)\n",
    "    df['Squad_xG'] = df.get('Agg_xG', 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare Data\n",
    "ucl_df = historical_df[historical_df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "# Aggregate player stats\n",
    "player_agg = historical_df.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={\n",
    "    'Gls_league': 'Agg_Gls_league', \n",
    "    'xG_player': 'Agg_xG'\n",
    "})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "ucl_df = engineer_elite_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "# Define Features\n",
    "features = ['Adj_Pts_Per_Game', 'Adj_GD_Per_Game', 'Is_Big_5', 'Squad_Goals', 'Squad_xG']\n",
    "for col in features:\n",
    "    if col not in team_level_df.columns: team_level_df[col] = 0\n",
    "\n",
    "X = team_level_df[features].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAINING (Elite Ensemble)\n",
    "# ==============================================================================\n",
    "print(\"Training Elite Ensemble...\")\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ucl_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ucl_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# Optimal Threshold\n",
    "probs = ucl_model.predict_proba(X_test_sc)[:, 1]\n",
    "best_thresh, best_f1 = 0.5, 0\n",
    "for t in np.arange(0.1, 0.9, 0.05):\n",
    "    preds = (probs >= t).astype(int)\n",
    "    score = f1_score(y_test, preds)\n",
    "    if score > best_f1: best_f1, best_thresh = score, t\n",
    "\n",
    "print(f\"üèÜ Optimal Threshold: {best_thresh:.2f}\")\n",
    "print(\"\\n--- Elite Model Report ---\")\n",
    "print(classification_report(y_test, (probs >= best_thresh).astype(int), target_names=['Not Winner', 'Winner']))\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2026 UCL Winner Prediction ---\")\n",
    "try:\n",
    "    # Load 2026 data\n",
    "    d_p = pd.read_csv('../data/combined_player_stats_2026.csv')\n",
    "    d_l = pd.read_csv('../data/combined_league_standings_2026.csv')\n",
    "    d_up = pd.read_csv('../data/ucl_team_progress_2026.csv')\n",
    "    d_us = pd.read_csv('../data/ucl_player_stats_2026.csv')\n",
    "    \n",
    "    current_season = '2025-2026'\n",
    "    for d in [d_p, d_l, d_up, d_us]: \n",
    "        d['Season']=current_season; d.columns=d.columns.str.strip()\n",
    "        if 'Squad' in d.columns: d['Squad']=d['Squad'].str.strip().replace({'Paris S-G':'Paris Saint-Germain','Inter':'Internazionale','Manchester Utd':'Manchester United','Leverkusen':'Bayer Leverkusen'})\n",
    "\n",
    "    m_k = ['Squad', 'Season']\n",
    "    if 'League' in d_p.columns and 'League' in d_l.columns: m_k.append('League')\n",
    "    df_26 = pd.merge(d_p, d_l, on=m_k, how='left', suffixes=('_player', '_team'))\n",
    "    df_26 = pd.merge(df_26, d_us[['Player','Squad','Season']], on=['Player','Squad','Season'], how='left')\n",
    "    df_26 = pd.merge(df_26, d_up, on=['Squad','Season'], how='left')\n",
    "    if 'UCL_Progress' in df_26.columns: df_26.rename(columns={'UCL_Progress':'UCL_progress'}, inplace=True)\n",
    "    df_26['UCL_progress'].fillna('Did Not Qualify', inplace=True)\n",
    "    \n",
    "    ucl_26 = df_26[df_26['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "    rename_26 = {'Gls':'Gls_league', 'xG':'xG_player', 'Pts':'Pts', 'MP':'MP_team', 'W':'W', 'GD':'GD', 'Rk':'Rk_team'}\n",
    "    ucl_26.rename(columns=rename_26, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Aggregation\n",
    "    p_agg = ucl_26.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Agg_Gls_league', 'xG_player': 'Agg_xG'})\n",
    "    ucl_26 = pd.merge(ucl_26, p_agg, on=['Squad', 'Season'], how='left')\n",
    "    ucl_26 = ucl_26.drop_duplicates(subset=['Squad'])\n",
    "    \n",
    "    # Feature Engineering (Now Safe against missing 'League' column)\n",
    "    ucl_26 = engineer_elite_features(ucl_26)\n",
    "    \n",
    "    # Select Best Features & Scale\n",
    "    for col in features:\n",
    "        if col not in ucl_26.columns: ucl_26[col] = 0\n",
    "    \n",
    "    X_live = ucl_26[features].fillna(0)\n",
    "    # Use the same scaler from training!\n",
    "    X_live_sc = pd.DataFrame(scaler.transform(X_live), columns=features)\n",
    "    \n",
    "    # Predict\n",
    "    ucl_26['Win_Prob'] = ucl_model.predict_proba(X_live_sc)[:, 1]\n",
    "    print(\"Top 10 Contenders:\")\n",
    "    cols = ['Squad', 'Win_Prob']\n",
    "    if 'League' in ucl_26.columns: cols.insert(1, 'League')\n",
    "    display(ucl_26[cols].sort_values(by='Win_Prob', ascending=False).head(10))\n",
    "\n",
    "except Exception as e: print(f\"Prediction Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a50b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training UCL Ensemble Model ---\n",
      "‚úÖ Ensemble Model Trained.\n",
      "\n",
      ">>> Evaluating UCL Winner Model...\n",
      "\n",
      "--- Advanced Evaluation: Ensemble ---\n",
      "üèÜ Optimal Threshold: 0.2140\n",
      "   Max F1-Score: 0.1429\n",
      "   Precision at Optimal: 0.0909\n",
      "   Recall at Optimal:    0.3333\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 28.3\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Train and Evaluate UCL Ensemble Model ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training UCL Ensemble Model ---\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Data not found!\")\n",
    "\n",
    "# 2. Feature Engineering (Elite UCL)\n",
    "def engineer_ucl_features(df):\n",
    "    df = df.copy()\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Pts_Per_Game'] = df['Pts'] / df['MP_team']\n",
    "    df['Goal_Diff_Per_Game'] = df['GD'] / df['MP_team']\n",
    "    df['Win_Rate'] = df['W'] / df['MP_team']\n",
    "    df['Dominance_Score'] = (df['Win_Rate'] * 0.7) + (df['Goal_Diff_Per_Game'] * 0.3)\n",
    "    df['League_Pedigree'] = 1 / df['Rk_team'].replace(0, 20)\n",
    "    return df\n",
    "\n",
    "# 3. Prepare Team-Level Data\n",
    "ucl_df = df[df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "player_agg = df.groupby(['Squad', 'Season'])[['Gls_league', 'Ast_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Squad_Goals', 'Ast_league': 'Squad_Ast', 'xG_player': 'Squad_xG'})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "\n",
    "ucl_df = engineer_ucl_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "features_ucl = ['Pts_Per_Game', 'Goal_Diff_Per_Game', 'Win_Rate', 'Dominance_Score', 'League_Pedigree', 'Squad_Goals', 'Squad_xG', 'xG_team']\n",
    "# Handle missing xG_team for old seasons\n",
    "if 'xG_team' not in team_level_df.columns: team_level_df['xG_team'] = 0\n",
    "\n",
    "X = team_level_df[features_ucl].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Train Ensemble\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42, eval_metric='logloss')\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ensemble_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Ensemble Model Trained.\")\n",
    "\n",
    "# 5. Run Advanced Evaluation (Using your function)\n",
    "if 'evaluate_model_advanced' in locals():\n",
    "    print(\"\\n>>> Evaluating UCL Winner Model...\")\n",
    "    evaluate_model_advanced(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "    calculate_top_k_proxy(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è evaluation functions not found. Please run the previous cell containing 'evaluate_model_advanced'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb828a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Advanced Evaluation: Deep Learning (Ballon d'Or) ---\n",
      "üèÜ Optimal Threshold: 0.7485\n",
      "   Max F1-Score: 0.2857\n",
      "   Precision at Optimal: 0.3333\n",
      "   Recall at Optimal:    0.2500\n",
      "\n",
      "--- Advanced Evaluation: Ensemble (UCL) ---\n",
      "üèÜ Optimal Threshold: 0.0140\n",
      "   Max F1-Score: 0.1290\n",
      "   Precision at Optimal: 0.0714\n",
      "   Recall at Optimal:    0.6667\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Deep Learning): 171.2\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 30.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# --- 1. Define the Advanced Evaluation Function (FIXED) ---\n",
    "def evaluate_model_advanced(model, X_test, y_test, model_type=\"Deep Learning\"):\n",
    "    print(f\"\\n--- Advanced Evaluation: {model_type} ---\")\n",
    "    \n",
    "    # Get Probabilities\n",
    "    # FIX: Check if \"Deep Learning\" is IN the string, not just equal to it\n",
    "    if \"Deep Learning\" in model_type:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X_test, torch.Tensor):\n",
    "                X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "            # Forward pass + Sigmoid\n",
    "            probs = torch.sigmoid(model(X_test)).numpy().flatten()\n",
    "            \n",
    "            if isinstance(y_test, torch.Tensor):\n",
    "                y_true = y_test.numpy().flatten()\n",
    "            else:\n",
    "                y_true = y_test\n",
    "    else: # Ensemble / XGBoost\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        y_true = y_test\n",
    "\n",
    "    # 2. Find Optimal Threshold (Maximize F1)\n",
    "    # Handle NaNs in y_true (just in case)\n",
    "    mask = ~np.isnan(y_true)\n",
    "    y_true = y_true[mask]\n",
    "    probs = probs[mask]\n",
    "    \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, probs)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    # Safety check for index bounds\n",
    "    if best_idx < len(thresholds):\n",
    "        best_thresh = thresholds[best_idx]\n",
    "    else:\n",
    "        best_thresh = 0.5\n",
    "        \n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    \n",
    "    print(f\"üèÜ Optimal Threshold: {best_thresh:.4f}\")\n",
    "    print(f\"   Max F1-Score: {best_f1:.4f}\")\n",
    "    print(f\"   Precision at Optimal: {precisions[best_idx]:.4f}\")\n",
    "    print(f\"   Recall at Optimal:    {recalls[best_idx]:.4f}\")\n",
    "\n",
    "    return best_thresh\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. RUN ADVANCED EVALUATION (with Reconstructed Data)\n",
    "# ==============================================================================\n",
    "\n",
    "# Note: We assume the data reconstruction part from the previous cell ran successfully\n",
    "# and X_test_b_tensor, y_test_b_tensor, X_test_u_scaled, y_test_u are available.\n",
    "\n",
    "if 'model' in locals():\n",
    "    # Fix: String matching is now handled inside the function\n",
    "    best_thresh_bdo = evaluate_model_advanced(model, X_test_b_tensor, y_test_b, \"Deep Learning (Ballon d'Or)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'model' (Deep Learning) not found in memory.\")\n",
    "\n",
    "if 'ensemble_model' in locals():\n",
    "    best_thresh_ucl = evaluate_model_advanced(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble (UCL)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'ensemble_model' not found in memory.\")\n",
    "\n",
    "\n",
    "# --- 3. Top-K Accuracy Proxy ---\n",
    "def calculate_top_k_proxy(model, X, y, model_type=\"Deep Learning\"):\n",
    "    if model_type == \"Deep Learning\":\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "             if not isinstance(X, torch.Tensor): X = torch.tensor(X, dtype=torch.float32)\n",
    "             probs = torch.sigmoid(model(X)).numpy().flatten()\n",
    "    else:\n",
    "        probs = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    results = pd.DataFrame({'Actual': y, 'Prob': probs})\n",
    "    winners = results[results['Actual'] == 1]\n",
    "    \n",
    "    if not winners.empty:\n",
    "        results['Rank'] = results['Prob'].rank(ascending=False)\n",
    "        avg_winner_rank = results[results['Actual'] == 1]['Rank'].mean()\n",
    "        print(f\"\\nüìä Average Rank of True Winners in Test Set ({model_type}): {avg_winner_rank:.1f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No winners found in test set for {model_type}.\")\n",
    "\n",
    "if 'model' in locals(): calculate_top_k_proxy(model, X_test_b_tensor, y_test_b, \"Deep Learning\")\n",
    "if 'ensemble_model' in locals(): calculate_top_k_proxy(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
